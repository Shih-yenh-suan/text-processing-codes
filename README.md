# 文本处理工具

## 文本预处理工具

### 第 1 步：删除非中文字符.py

输入：输入文件夹、输出文件夹路径

根据正则表达式，去除输入文件夹内所有 .txt 文件中的全部非中文字符，用于文本分析

### 第 2 步：中文简繁转换.py

输入：输入文件夹、输出文件夹路径

使用 langdetect 模块，检查输入文件夹中所有 .txt 的文本语言

对于繁体文件，将其转换为简体，用于文本分析

### 第 3 步：去除停用词.py

输入：文本文件夹、停用词词典路径、输出文本文件夹

文本文件夹中有多个 .txt 文件
停用词词典中，每个停用词分行排列，一行一个

删除文本文件夹中 .txt 文件的停用词。

本步骤需要在分词之前进行。

### 第 4 步：jieba分词.py

输入：文本文件夹、输出文本文件夹、自定义词典

使用 jieba 模块，对文本文件夹中所有 .txt 文本进行分词

将分词后的文本存入输出文本文件夹。

### 第 5 步：去除文本单字词.py

输入：输入文件夹、输出文件夹路径

遍历输入文件夹中的所有 .txt 文件。这些文件已经经过了 jieba 分词处理，每个词按照空格分隔

删除其中的单字词

输出：删除了单字词的 .txt 文件

### 第 6 步：检索高频词.py

输入：输入文件夹、输出txt文件

对于每个输入文件夹中的 .txt 文件，统计：
1. 全部行中出现的词
2. 出现频率最高的前 0.1% 的词
3. 仅在全部样本中出现一次的词。

将这些词输出到输出txt文件词典中。

### 第 7 步：去除高频词.py

输入：输入文件夹路径、输出文件夹路径、词典

删除输入文件夹路径中所有 .txt 文件中出现在词典中的词。
保存到输出文件夹路径下

## 需要执行预处理后才能进行的程序

### 训练LDA模型 (含多线程).py

输入： LDA 模型的模型数区间、数据集路径、输出 xlsx 文件路径、迭代次数

训练模型，将模型数和对应的困惑度保存到 xlsx 文件中。

注意：困惑度根据定义手动计算

### 按关键词保留对应语句.py

输入：文本文件夹、输出文本文件夹、关键词词典

对于文本文件夹中所有的 .txt 文件，仅保留中文、英文、数字、重要标点
按照重要标点分行

保留包含关键词的行

保存并输出

### 计算文本词频.py

输入：文本文件夹、关键词文本

统计文本文件夹中各个 .txt 文本的词频

输出到 excel 表格

